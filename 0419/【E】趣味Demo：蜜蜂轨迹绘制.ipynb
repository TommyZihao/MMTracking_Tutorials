{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d2a938c-8c6b-481f-9ccb-eef8bba5111e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 单目标追踪 Single Object Tracking （SOT）\n",
    "# 趣味Demo：蜜蜂轨迹绘制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e504dadb-d493-4bfe-8819-e21421470ade",
   "metadata": {},
   "source": [
    "参考教程：https://github.com/open-mmlab/mmtracking/blob/master/docs/en/quick_run.md\n",
    "\n",
    "MMtracking 预训练模型库 Model Zoo：https://mmtracking.readthedocs.io/en/latest/model_zoo.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d450ea5b-2861-4d28-8202-54340008b58c",
   "metadata": {},
   "source": [
    "## 进入 MMTracking 主目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d2b4c5-938e-4ea8-816a-f17e843bf3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.circleci',\n",
       " '.dev_scripts',\n",
       " '.github',\n",
       " '.gitignore',\n",
       " '.pre-commit-config.yaml',\n",
       " '.readthedocs.yml',\n",
       " 'CITATION.cff',\n",
       " 'LICENSE',\n",
       " 'MANIFEST.in',\n",
       " 'README.md',\n",
       " 'README_zh-CN.md',\n",
       " 'configs',\n",
       " 'demo',\n",
       " 'docker',\n",
       " 'docs',\n",
       " 'mmtrack',\n",
       " 'model-index.yml',\n",
       " 'requirements.txt',\n",
       " 'requirements',\n",
       " 'resources',\n",
       " 'setup.cfg',\n",
       " 'setup.py',\n",
       " 'tests',\n",
       " 'tools',\n",
       " 'mmtrack.egg-info',\n",
       " 'checkpoints',\n",
       " 'outputs',\n",
       " 'data']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('mmtracking')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f95177-53df-4e3d-b561-41ab7c1f05fb",
   "metadata": {},
   "source": [
    "## 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21e1823a-d785-4a33-90da-819f28e6340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv-python\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 导入python绘图matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# 使用ipython的魔法方法，将绘制出的图像直接嵌入在notebook单元格中\n",
    "%matplotlib inline\n",
    "\n",
    "# 定义可视化图像函数\n",
    "def show_img_from_array(img):\n",
    "    '''opencv读入图像格式为BGR，matplotlib可视化格式为RGB，因此需将BGR转RGB'''\n",
    "    img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_RGB)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9146bb0-0a37-412b-8daa-7dab7a26618e",
   "metadata": {},
   "source": [
    "## 在本地运行`【D】获取视频第一帧单目标检测框.ipynb`，将坐标复制粘贴至`data/gt_box_file.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02bf84a1-206c-4645-b0b6-904709a41294",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229, 296, 8, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 参考\n",
    "\n",
    "# bee.mp4\n",
    "# 第一只蜜蜂：132, 59, 57, 61\n",
    "# 第二只蜜蜂：694, 151, 87, 79\n",
    "# 第三只蜜蜂：1266, 462, 12, 35\n",
    "\n",
    "# billiards1.mp4\n",
    "336, 401, 14, 14\n",
    "\n",
    "# billiards2.mp4\n",
    "229, 296, 8, 8\n",
    "\n",
    "# billiards3.mp4\n",
    "# 左边白球：325, 64, 12, 13\n",
    "# 右边白球：339, 63, 12, 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525130d9-1f55-42d6-8352-043ac8e77599",
   "metadata": {},
   "source": [
    "## Python API 方式实现（多个目标轨迹绘制）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f19325ce-fdb8-4ac8-983d-5a6256c8d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import tempfile\n",
    "from mmtrack.apis import inference_sot, init_model\n",
    "\n",
    "import seaborn as sns\n",
    "import random\n",
    "# 生成调色板\n",
    "palette = sns.color_palette('hls', 20)\n",
    "def get_color(seed):\n",
    "    random.seed(seed)\n",
    "    # 从调色板中随机挑选一种颜色\n",
    "    bbox_color = random.choice(palette)\n",
    "    bbox_color = [int(255 * c) for c in bbox_color][::-1]\n",
    "    return bbox_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7f39aaa-55bf-45d0-957e-321536f945fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 15:37:29,353 - mmtrack - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
      "2022-04-19 15:37:29,354 - mmcv - INFO - load model from: torchvision://resnet50\n",
      "2022-04-19 15:37:29,354 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50\n",
      "2022-04-19 15:37:29,428 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: layer4.0.conv1.weight, layer4.0.bn1.running_mean, layer4.0.bn1.running_var, layer4.0.bn1.weight, layer4.0.bn1.bias, layer4.0.conv2.weight, layer4.0.bn2.running_mean, layer4.0.bn2.running_var, layer4.0.bn2.weight, layer4.0.bn2.bias, layer4.0.conv3.weight, layer4.0.bn3.running_mean, layer4.0.bn3.running_var, layer4.0.bn3.weight, layer4.0.bn3.bias, layer4.0.downsample.0.weight, layer4.0.downsample.1.running_mean, layer4.0.downsample.1.running_var, layer4.0.downsample.1.weight, layer4.0.downsample.1.bias, layer4.1.conv1.weight, layer4.1.bn1.running_mean, layer4.1.bn1.running_var, layer4.1.bn1.weight, layer4.1.bn1.bias, layer4.1.conv2.weight, layer4.1.bn2.running_mean, layer4.1.bn2.running_var, layer4.1.bn2.weight, layer4.1.bn2.bias, layer4.1.conv3.weight, layer4.1.bn3.running_mean, layer4.1.bn3.running_var, layer4.1.bn3.weight, layer4.1.bn3.bias, layer4.2.conv1.weight, layer4.2.bn1.running_mean, layer4.2.bn1.running_var, layer4.2.bn1.weight, layer4.2.bn1.bias, layer4.2.conv2.weight, layer4.2.bn2.running_mean, layer4.2.bn2.running_var, layer4.2.bn2.weight, layer4.2.bn2.bias, layer4.2.conv3.weight, layer4.2.bn3.running_mean, layer4.2.bn3.running_var, layer4.2.bn3.weight, layer4.2.bn3.bias, fc.weight, fc.bias\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmtracking/sot/stark/stark_st2_r50_50e_lasot/stark_st2_r50_50e_lasot_20220416_170201-b1484149.pth\n"
     ]
    }
   ],
   "source": [
    "# 输入输出视频路径\n",
    "input_video = 'data/bee.mp4'\n",
    "output = 'outputs/output_C5_SOT_bee_trace.mp4'\n",
    "\n",
    "# 指定单目标追踪算法 config 配置文件\n",
    "sot_config = './configs/sot/stark/stark_st2_r50_50e_lasot.py'\n",
    "# 指定单目标检测算法的模型权重文件\n",
    "sot_checkpoint = 'https://download.openmmlab.com/mmtracking/sot/stark/stark_st2_r50_50e_lasot/stark_st2_r50_50e_lasot_20220416_170201-b1484149.pth'\n",
    "# 初始化单目标追踪模型\n",
    "sot_model = init_model(sot_config, sot_checkpoint, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d719ce5-ee25-4194-957f-a05bebbe28a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有3个待追踪目标\n"
     ]
    }
   ],
   "source": [
    "# 指定多个目标的初始矩形框坐标 [x, y, w, h]\n",
    "init_bbox_xywh = [[132, 59, 57, 61], [694, 151, 87, 79], [1266, 462, 12, 35]]\n",
    "\n",
    "# 目标个数\n",
    "ID_num = len(init_bbox_xywh)\n",
    "print('共有{}个待追踪目标'.format(ID_num))\n",
    "\n",
    "# 转成 [x1, y1, x2, y2 ]\n",
    "init_bbox_xyxy = []\n",
    "for each in init_bbox_xywh:\n",
    "    init_bbox_xyxy.append([each[0], each[1], each[0]+each[2], each[1]+each[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55bf6cbc-9524-48ab-b60a-68a91a91d6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始逐帧处理\n",
      "\n",
      "\n",
      "追踪第1个目标\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 766/774, 16.7 task/s, elapsed: 46s, ETA:     0s\n",
      "\n",
      "追踪第2个目标\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 766/774, 18.5 task/s, elapsed: 41s, ETA:     0s\n",
      "\n",
      "追踪第3个目标\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 766/774, 17.6 task/s, elapsed: 43s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "# 读入待预测视频\n",
    "imgs = mmcv.VideoReader(input_video)\n",
    "# prog_bar = mmcv.ProgressBar(len(imgs))\n",
    "out_dir = tempfile.TemporaryDirectory()\n",
    "out_path = out_dir.name\n",
    "\n",
    "## 获取每帧的追踪结果\n",
    "# 逐帧输入模型预测\n",
    "circle_coord_list = {}\n",
    "print('开始逐帧处理')\n",
    "\n",
    "for ID in range(ID_num): # 遍历每个待追踪目标\n",
    "    print('\\n')\n",
    "    print('追踪第{}个目标'.format(ID+1))\n",
    "    circle_coord_list[ID] = {}\n",
    "    circle_coord_list[ID]['bbox'] = []\n",
    "    circle_coord_list[ID]['trace'] = []\n",
    "    \n",
    "    # 启动进度条\n",
    "    prog_bar = mmcv.ProgressBar(len(imgs))\n",
    "    \n",
    "    for i, img in enumerate(imgs): # 遍历视频每一帧\n",
    "        \n",
    "        # 执行单目标追踪\n",
    "        result = inference_sot(sot_model, img, init_bbox_xyxy[ID], frame_id=i)\n",
    "        # 目标检测矩形框坐标\n",
    "        result_bbox = np.array(result['track_bboxes'][:4].astype('uint32'))\n",
    "        # 保存矩形框坐标\n",
    "        circle_coord_list[ID]['bbox'].append(result_bbox)\n",
    "        \n",
    "\n",
    "        # 获取矩形框中心点轨迹点坐标\n",
    "        circle_x = int((result_bbox[0] + result_bbox[2]) / 2)\n",
    "        circle_y = int((result_bbox[1] + result_bbox[3]) / 2)\n",
    "        # 保存轨迹点坐标\n",
    "        circle_coord_list[ID]['trace'].append(np.array([circle_x, circle_y]))\n",
    "        \n",
    "        prog_bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b832938-1dcd-4825-9c1b-c2b83abb5179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 766/774, 50.7 task/s, elapsed: 15s, ETA:     0s导出视频，FPS 30.0\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 766/766, 56.8 task/s, elapsed: 13s, ETA:     0s\n",
      "已成功导出视频 至 outputs/output_C5_SOT_bee_trace.mp4\n"
     ]
    }
   ],
   "source": [
    "## 可视化\n",
    "\n",
    "# 启动进度条\n",
    "prog_bar = mmcv.ProgressBar(len(imgs))\n",
    "\n",
    "for i, img in enumerate(imgs): # 遍历视频每一帧\n",
    "    img_draw = img.copy()\n",
    "    \n",
    "    for ID in range(ID_num): # 遍历每个待追踪目标\n",
    "        # 获取该目标的专属颜色\n",
    "        ID_color = get_color(ID)\n",
    "        \n",
    "        result_bbox = circle_coord_list[ID]['bbox'][i]\n",
    "        \n",
    "        # 绘制目标检测矩形框：图像，左上角坐标，右下角坐标，颜色，线宽\n",
    "        img_draw = cv2.rectangle(img_draw, (result_bbox[0], result_bbox[1]), (result_bbox[2], result_bbox[3]), ID_color, 3)  \n",
    "\n",
    "        # 绘制从第一帧到当前帧的轨迹\n",
    "        for each in circle_coord_list[ID]['trace'][:i]:\n",
    "            # 绘制圆，指定圆心坐标和半径，红色，最后一个参数为线宽，-1表示填充\n",
    "            img_draw = cv2.circle(img_draw, (each[0],each[1]), 3,  ID_color, -1)\n",
    "    \n",
    "    # 将当前帧的可视化效果保存为图片文件\n",
    "    cv2.imwrite(f'{out_path}/{i:06d}.jpg', img_draw)\n",
    "    prog_bar.update()\n",
    "    \n",
    "# 将保存下来的各帧图片文件串成视频\n",
    "print('导出视频，FPS {}'.format(imgs.fps))\n",
    "mmcv.frames2video(out_path, output, fps=imgs.fps, fourcc='mp4v')\n",
    "print('已成功导出视频 至 {}'.format(output))\n",
    "out_dir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7961250a-a112-4521-9f8c-648fe203eb74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
