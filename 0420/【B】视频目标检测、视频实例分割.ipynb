{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf347f35-7b0e-413f-9f16-9c5cf5f556af",
   "metadata": {},
   "source": [
    "# 视频目标检测、视频实例分割"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b43d2ef-0c72-47d0-9b34-05ef25beb925",
   "metadata": {},
   "source": [
    "调用预训练追踪模型对图像和视频预测\n",
    "\n",
    "代码测试云GPU环境：[featurize](https://featurize.cn?s=d7ce99f842414bfcaea5662a97581bd1)，在云GPU中直接运行本notebook的所有代码即可\n",
    "\n",
    "OpenMMLab主页：https://openmmlab.com/\n",
    "\n",
    "MMTracking主页：https://github.com/open-mmlab/mmtracking\n",
    "\n",
    "MMDetection主页：https://github.com/open-mmlab/mmdetection\n",
    "\n",
    "2022-03-05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e504dadb-d493-4bfe-8819-e21421470ade",
   "metadata": {},
   "source": [
    "## 文档链接\n",
    "\n",
    "参考教程：https://github.com/open-mmlab/mmtracking/blob/master/docs/en/quick_run.md\n",
    "\n",
    "MMtracking 预训练模型库 Model Zoo：https://mmtracking.readthedocs.io/en/latest/model_zoo.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fd5643-04d5-47bc-8c05-c0d62429e28d",
   "metadata": {},
   "source": [
    "## 进入 MMTracking 主目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d2b4c5-938e-4ea8-816a-f17e843bf3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.circleci',\n",
       " '.dev_scripts',\n",
       " '.github',\n",
       " '.gitignore',\n",
       " '.pre-commit-config.yaml',\n",
       " '.readthedocs.yml',\n",
       " 'CITATION.cff',\n",
       " 'LICENSE',\n",
       " 'MANIFEST.in',\n",
       " 'README.md',\n",
       " 'README_zh-CN.md',\n",
       " 'configs',\n",
       " 'demo',\n",
       " 'docker',\n",
       " 'docs',\n",
       " 'mmtrack',\n",
       " 'model-index.yml',\n",
       " 'requirements.txt',\n",
       " 'requirements',\n",
       " 'resources',\n",
       " 'setup.cfg',\n",
       " 'setup.py',\n",
       " 'tests',\n",
       " 'tools',\n",
       " 'mmtrack.egg-info',\n",
       " 'checkpoints',\n",
       " 'outputs',\n",
       " 'data']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('mmtracking')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11b3791-5e63-43f1-a529-21a344f2de67",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 视频目标检测 Video Object Detection （VID）\n",
    "\n",
    "模型的 config 文件需和 checkpoint 权重文件 一一对应，比如下面这样：\n",
    "\n",
    "| 模型                           | config文件                                                       | checkpoint权重文件                                                   |\n",
    "| ------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n",
    "| SELSA (ICCV 2019)              | configs/vid/selsa/selsa_faster_rcnn_r101_dc5_1x_imagenetvid.py | https://download.openmmlab.com/mmtracking/vid/selsa/selsa_faster_rcnn_r101_dc5_1x_imagenetvid/selsa_faster_rcnn_r101_dc5_1x_imagenetvid_20201218_172724-aa961bcc.pth |\n",
    "| Temporal RoI Align (AAAI 2021) | configs/vid/temporal_roi_align/selsa_troialign_faster_rcnn_x101_dc5_7e_imagenetvid.py | https://download.openmmlab.com/mmtracking/vid/temporal_roi_align/selsa_troialign_faster_rcnn_x101_dc5_7e_imagenetvid/selsa_troialign_faster_rcnn_x101_dc5_7e_imagenetvid_20210822_164036-4471ac42.pth |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048d3e60-865c-407d-875d-618bed366960",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 命令行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ae21b03-ee13-44a4-9ea2-c8a8e825d85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-19 20:57:04,509 - mmtrack - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet101'}\n",
      "2022-04-19 20:57:04,509 - mmcv - INFO - load model from: torchvision://resnet101\n",
      "2022-04-19 20:57:04,510 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet101\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /home/featurize/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
      "100%|█████████████████████████████████████████| 171M/171M [00:01<00:00, 113MB/s]\n",
      "2022-04-19 20:57:06,271 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "2022-04-19 20:57:06,294 - mmtrack - INFO - initialize ChannelMapper with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "2022-04-19 20:57:06,345 - mmtrack - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
      "2022-04-19 20:57:06,359 - mmtrack - INFO - initialize SelsaBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmtracking/vid/selsa/selsa_faster_rcnn_r101_dc5_1x_imagenetvid/selsa_faster_rcnn_r101_dc5_1x_imagenetvid_20201218_172724-aa961bcc.pth\n",
      "Downloading: \"https://download.openmmlab.com/mmtracking/vid/selsa/selsa_faster_rcnn_r101_dc5_1x_imagenetvid/selsa_faster_rcnn_r101_dc5_1x_imagenetvid_20201218_172724-aa961bcc.pth\" to /home/featurize/.cache/torch/hub/checkpoints/selsa_faster_rcnn_r101_dc5_1x_imagenetvid_20201218_172724-aa961bcc.pth\n",
      "100%|█████████████████████████████████████████| 342M/342M [00:03<00:00, 113MB/s]\n",
      "[                                                  ] 0/99, elapsed: 0s, ETA:/home/featurize/work/MMTracking教程/0419/mmtracking/mmtrack/datasets/pipelines/formatting.py:138: UserWarning: The 'ConcatVideoReferences' class will be deprecated in the future, please use 'ConcatSameTypeFrames' instead\n",
      "  \"The 'ConcatVideoReferences' class will be deprecated in the \"\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 6.2 task/s, elapsed: 16s, ETA:     0s\n",
      "making the output video at outputs/output_B1_VID_SELSA.mp4 with a FPS of 24\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 29.9 task/s, elapsed: 3s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "!python ./demo/demo_vid.py \\\n",
    "    ./configs/vid/selsa/selsa_faster_rcnn_r101_dc5_1x_imagenetvid.py \\\n",
    "    --checkpoint https://download.openmmlab.com/mmtracking/vid/selsa/selsa_faster_rcnn_r101_dc5_1x_imagenetvid/selsa_faster_rcnn_r101_dc5_1x_imagenetvid_20201218_172724-aa961bcc.pth \\\n",
    "    --input data/mot_people_short.mp4 \\\n",
    "    --output outputs/output_B1_VID_SELSA.mp4 \\\n",
    "    --score-thr 0.4 \\\n",
    "    --thickness 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b760d812-1da3-441b-b800-c30855ad5119",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53ac980c-aaad-4f35-b0fe-55278b31d7d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 21:00:23,866 - mmtrack - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet101'}\n",
      "2022-04-19 21:00:23,868 - mmcv - INFO - load model from: torchvision://resnet101\n",
      "2022-04-19 21:00:23,868 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet101\n",
      "2022-04-19 21:00:24,048 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "2022-04-19 21:00:24,077 - mmtrack - INFO - initialize ChannelMapper with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "2022-04-19 21:00:24,132 - mmtrack - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
      "2022-04-19 21:00:24,147 - mmtrack - INFO - initialize SelsaBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmtracking/vid/selsa/selsa_faster_rcnn_r101_dc5_1x_imagenetvid/selsa_faster_rcnn_r101_dc5_1x_imagenetvid_20201218_172724-aa961bcc.pth\n",
      "[                                                  ] 0/99, elapsed: 0s, ETA:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/featurize/work/MMTracking教程/0419/mmtracking/mmtrack/datasets/pipelines/formatting.py:138: UserWarning: The 'ConcatVideoReferences' class will be deprecated in the future, please use 'ConcatSameTypeFrames' instead\n",
      "  \"The 'ConcatVideoReferences' class will be deprecated in the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 6.2 task/s, elapsed: 16s, ETA:     0s\n",
      " making the output video at outputs/output_B2_VID_SELSA.mp4 with a FPS of 24.652929091701427\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 28.7 task/s, elapsed: 3s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "import tempfile\n",
    "from mmtrack.apis import inference_vid, init_model\n",
    "\n",
    "# 输入输出视频路径\n",
    "input_video = 'data/mot_people_short.mp4'\n",
    "output = 'outputs/output_B2_VID_SELSA.mp4'\n",
    "\n",
    "# 指定 config 配置文件 和 模型权重文件，创建模型\n",
    "vid_config = './configs/vid/selsa/selsa_faster_rcnn_r101_dc5_1x_imagenetvid.py'\n",
    "vid_checkpoint = 'https://download.openmmlab.com/mmtracking/vid/selsa/selsa_faster_rcnn_r101_dc5_1x_imagenetvid/selsa_faster_rcnn_r101_dc5_1x_imagenetvid_20201218_172724-aa961bcc.pth'\n",
    "vid_model = init_model(vid_config, vid_checkpoint, device='cuda:0')\n",
    "\n",
    "# 读入待预测视频\n",
    "imgs = mmcv.VideoReader(input_video)\n",
    "prog_bar = mmcv.ProgressBar(len(imgs))\n",
    "out_dir = tempfile.TemporaryDirectory()\n",
    "out_path = out_dir.name\n",
    "\n",
    "# 逐帧输入模型预测\n",
    "for i, img in enumerate(imgs):\n",
    "    result = inference_vid(vid_model, img, frame_id=i)\n",
    "    vid_model.show_result(\n",
    "            img,\n",
    "            result,\n",
    "            wait_time=int(1000. / imgs.fps),\n",
    "            out_file=f'{out_path}/{i:06d}.jpg')\n",
    "    prog_bar.update()\n",
    "\n",
    "# 生成预测视频\n",
    "print(f'\\n making the output video at {output} with a FPS of {imgs.fps}')\n",
    "mmcv.frames2video(out_path, output, fps=imgs.fps, fourcc='mp4v')\n",
    "out_dir.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2ba7b-7206-4ca4-acf8-67959c77c86c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 视频实例分割 Video Instance Segmentat （VIS）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a8460-d436-4435-94ba-f7755db6f1d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 命令行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22dd1c9-938a-4c7e-8dd0-5b759a815b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-19 21:01:06,128 - mmtrack - INFO - initialize MaskRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth'}\n",
      "2022-04-19 21:01:06,128 - mmcv - INFO - load model from: https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth\n",
      "2022-04-19 21:01:06,129 - mmcv - INFO - load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth\n",
      "Downloading: \"https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth\" to /home/featurize/.cache/torch/hub/checkpoints/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth\n",
      "100%|█████████████████████████████████████████| 170M/170M [00:01<00:00, 111MB/s]\n",
      "2022-04-19 21:01:07,888 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([41, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([41]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([160, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([160]).\n",
      "size mismatch for roi_head.mask_head.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([40, 256, 1, 1]).\n",
      "size mismatch for roi_head.mask_head.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([40]).\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmtracking/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth\n",
      "Downloading: \"https://download.openmmlab.com/mmtracking/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth\" to /home/featurize/.cache/torch/hub/checkpoints/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth\n",
      "100%|█████████████████████████████████████████| 222M/222M [00:02<00:00, 111MB/s]\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 4.7 task/s, elapsed: 21s, ETA:     0smaking the output video at outputs/output_B2_VIS_masktrack_rcnn.mp4 with a FPS of 24\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 28.6 task/s, elapsed: 3s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "!python demo/demo_mot_vis.py \\\n",
    "        configs/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019.py \\\n",
    "        --checkpoint https://download.openmmlab.com/mmtracking/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth \\\n",
    "        --input data/mot_people_short.mp4 \\\n",
    "        --output outputs/output_B3_VIS_masktrack_rcnn.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276218f-702f-4e58-8546-ad4e9eb60bb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7abe056-fc39-44ea-a8af-e3384623f223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 21:03:35,301 - mmtrack - INFO - initialize MaskRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth'}\n",
      "2022-04-19 21:03:35,303 - mmcv - INFO - load model from: https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth\n",
      "2022-04-19 21:03:35,303 - mmcv - INFO - load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth\n",
      "2022-04-19 21:03:35,446 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([41, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([41]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([160, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([160]).\n",
      "size mismatch for roi_head.mask_head.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([40, 256, 1, 1]).\n",
      "size mismatch for roi_head.mask_head.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([40]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmtracking/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 4.9 task/s, elapsed: 20s, ETA:     0s\n",
      " making the output video at outputs/output_B4_VIS_masktrack_rcnn.mp4 with a FPS of 24.652929091701427\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 27.8 task/s, elapsed: 4s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "import tempfile\n",
    "from mmtrack.apis import inference_mot, init_model\n",
    "\n",
    "# 输入输出视频路径\n",
    "input_video = 'data/mot_people_short.mp4'\n",
    "output = 'outputs/output_B4_VIS_masktrack_rcnn.mp4'\n",
    "\n",
    "# 指定 config 配置文件 和 模型权重文件，创建模型\n",
    "vis_config = './configs/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019.py'\n",
    "vis_checkpoint = 'https://download.openmmlab.com/mmtracking/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth'\n",
    "vis_model = init_model(vis_config, vis_checkpoint, device='cuda:0')\n",
    "\n",
    "# 读入待预测视频\n",
    "imgs = mmcv.VideoReader(input_video)\n",
    "prog_bar = mmcv.ProgressBar(len(imgs))\n",
    "out_dir = tempfile.TemporaryDirectory()\n",
    "out_path = out_dir.name\n",
    "\n",
    "# 逐帧输入模型预测\n",
    "for i, img in enumerate(imgs):\n",
    "    result = inference_mot(vis_model, img, frame_id=i)\n",
    "    vis_model.show_result(\n",
    "            img,\n",
    "            result,\n",
    "            wait_time=int(1000. / imgs.fps),\n",
    "            out_file=f'{out_path}/{i:06d}.jpg')\n",
    "    prog_bar.update()\n",
    "    \n",
    "\n",
    "print(f'\\n making the output video at {output} with a FPS of {imgs.fps}')\n",
    "\n",
    "# 生成预测视频\n",
    "mmcv.frames2video(out_path, output, fps=imgs.fps, fourcc='mp4v')\n",
    "out_dir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c2467d-b944-4c50-babb-5ef7cfe6c7df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
