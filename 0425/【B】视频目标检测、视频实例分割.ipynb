{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf347f35-7b0e-413f-9f16-9c5cf5f556af",
   "metadata": {},
   "source": [
    "# 视频目标检测、视频实例分割"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b43d2ef-0c72-47d0-9b34-05ef25beb925",
   "metadata": {},
   "source": [
    "调用 MMTracking 预训练追踪模型，对视频做视频目标检测、视频实例分割。\n",
    "\n",
    "参考文档：https://github.com/open-mmlab/mmtracking/blob/master/docs/en/quick_run.md\n",
    "\n",
    "MMtracking 预训练模型库 Model Zoo：https://mmtracking.readthedocs.io/en/latest/model_zoo.html\n",
    "\n",
    "如果报错`CUDA out of memory.`则重启前面几个代码的`kernel`即可。\n",
    "\n",
    "作者：同济子豪兄 2022-03-05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fd5643-04d5-47bc-8c05-c0d62429e28d",
   "metadata": {},
   "source": [
    "## 进入 MMTracking 主目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d2b4c5-938e-4ea8-816a-f17e843bf3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.circleci',\n",
       " '.dev_scripts',\n",
       " '.github',\n",
       " '.gitignore',\n",
       " '.pre-commit-config.yaml',\n",
       " '.readthedocs.yml',\n",
       " 'CITATION.cff',\n",
       " 'LICENSE',\n",
       " 'MANIFEST.in',\n",
       " 'README.md',\n",
       " 'README_zh-CN.md',\n",
       " 'configs',\n",
       " 'demo',\n",
       " 'docker',\n",
       " 'docs',\n",
       " 'mmtrack',\n",
       " 'model-index.yml',\n",
       " 'requirements.txt',\n",
       " 'requirements',\n",
       " 'resources',\n",
       " 'setup.cfg',\n",
       " 'setup.py',\n",
       " 'tests',\n",
       " 'tools',\n",
       " 'mmtrack.egg-info',\n",
       " 'checkpoints',\n",
       " 'outputs',\n",
       " 'data']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('mmtracking')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11b3791-5e63-43f1-a529-21a344f2de67",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 视频目标检测 Video Object Detection （VID）\n",
    "\n",
    "模型的 config 文件需和 checkpoint 权重文件 一一对应，比如下面这样：\n",
    "\n",
    "| 模型                           | config文件                                                       | checkpoint权重文件                                                   |\n",
    "| ------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n",
    "| SELSA (ICCV 2019)              | configs/vid/selsa/selsa_faster_rcnn_r101_dc5_1x_imagenetvid.py | https://download.openmmlab.com/mmtracking/vid/selsa/selsa_faster_rcnn_r101_dc5_1x_imagenetvid/selsa_faster_rcnn_r101_dc5_1x_imagenetvid_20201218_172724-aa961bcc.pth |\n",
    "| Temporal RoI Align (AAAI 2021) | configs/vid/temporal_roi_align/selsa_troialign_faster_rcnn_x101_dc5_7e_imagenetvid.py | https://download.openmmlab.com/mmtracking/vid/temporal_roi_align/selsa_troialign_faster_rcnn_x101_dc5_7e_imagenetvid/selsa_troialign_faster_rcnn_x101_dc5_7e_imagenetvid_20210822_164036-4471ac42.pth |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048d3e60-865c-407d-875d-618bed366960",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 命令行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ae21b03-ee13-44a4-9ea2-c8a8e825d85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-21 13:00:29,908 - mmtrack - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet101'}\n",
      "2022-04-21 13:00:29,909 - mmcv - INFO - load model from: torchvision://resnet101\n",
      "2022-04-21 13:00:29,909 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet101\n",
      "2022-04-21 13:00:30,094 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "2022-04-21 13:00:30,121 - mmtrack - INFO - initialize ChannelMapper with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "2022-04-21 13:00:30,182 - mmtrack - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
      "2022-04-21 13:00:30,198 - mmtrack - INFO - initialize SelsaBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmtracking/vid/selsa/selsa_faster_rcnn_r101_dc5_1x_imagenetvid/selsa_faster_rcnn_r101_dc5_1x_imagenetvid_20201218_172724-aa961bcc.pth\n",
      "[                                                  ] 0/99, elapsed: 0s, ETA:/home/featurize/work/MMTracking教程/0420/mmtracking/mmtrack/datasets/pipelines/formatting.py:138: UserWarning: The 'ConcatVideoReferences' class will be deprecated in the future, please use 'ConcatSameTypeFrames' instead\n",
      "  \"The 'ConcatVideoReferences' class will be deprecated in the \"\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 4.6 task/s, elapsed: 22s, ETA:     0s\n",
      "making the output video at outputs/B1_VID_SELSA.mp4 with a FPS of 24\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 25.6 task/s, elapsed: 4s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "!python ./demo/demo_vid.py \\\n",
    "    ./configs/vid/selsa/selsa_faster_rcnn_r101_dc5_1x_imagenetvid.py \\\n",
    "    --checkpoint https://download.openmmlab.com/mmtracking/vid/selsa/selsa_faster_rcnn_r101_dc5_1x_imagenetvid/selsa_faster_rcnn_r101_dc5_1x_imagenetvid_20201218_172724-aa961bcc.pth \\\n",
    "    --input data/mot_people_short.mp4 \\\n",
    "    --output outputs/B1_VID_SELSA.mp4 \\\n",
    "    --score-thr 0.4 \\\n",
    "    --thickness 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b760d812-1da3-441b-b800-c30855ad5119",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ac980c-aaad-4f35-b0fe-55278b31d7d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 13:01:13,551 - mmtrack - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet101'}\n",
      "2022-04-21 13:01:13,554 - mmcv - INFO - load model from: torchvision://resnet101\n",
      "2022-04-21 13:01:13,555 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet101\n",
      "2022-04-21 13:01:13,791 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "2022-04-21 13:01:13,823 - mmtrack - INFO - initialize ChannelMapper with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "2022-04-21 13:01:13,882 - mmtrack - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
      "2022-04-21 13:01:13,901 - mmtrack - INFO - initialize SelsaBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmtracking/vid/selsa/selsa_faster_rcnn_r101_dc5_1x_imagenetvid/selsa_faster_rcnn_r101_dc5_1x_imagenetvid_20201218_172724-aa961bcc.pth\n",
      "[                                                  ] 0/99, elapsed: 0s, ETA:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/featurize/work/MMTracking教程/0420/mmtracking/mmtrack/datasets/pipelines/formatting.py:138: UserWarning: The 'ConcatVideoReferences' class will be deprecated in the future, please use 'ConcatSameTypeFrames' instead\n",
      "  \"The 'ConcatVideoReferences' class will be deprecated in the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 4.6 task/s, elapsed: 22s, ETA:     0s\n",
      " making the output video at outputs/B2_VID_SELSA.mp4 with a FPS of 24.652929091701427\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 25.9 task/s, elapsed: 4s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "import tempfile\n",
    "from mmtrack.apis import inference_vid, init_model\n",
    "\n",
    "# 输入输出视频路径\n",
    "input_video = 'data/mot_people_short.mp4'\n",
    "output = 'outputs/B2_VID_SELSA.mp4'\n",
    "\n",
    "# 指定 config 配置文件 和 模型权重文件，创建模型\n",
    "vid_config = './configs/vid/selsa/selsa_faster_rcnn_r101_dc5_1x_imagenetvid.py'\n",
    "vid_checkpoint = 'https://download.openmmlab.com/mmtracking/vid/selsa/selsa_faster_rcnn_r101_dc5_1x_imagenetvid/selsa_faster_rcnn_r101_dc5_1x_imagenetvid_20201218_172724-aa961bcc.pth'\n",
    "vid_model = init_model(vid_config, vid_checkpoint, device='cuda:0')\n",
    "\n",
    "# 读入待预测视频\n",
    "imgs = mmcv.VideoReader(input_video)\n",
    "prog_bar = mmcv.ProgressBar(len(imgs))\n",
    "out_dir = tempfile.TemporaryDirectory()\n",
    "out_path = out_dir.name\n",
    "\n",
    "# 逐帧输入模型预测\n",
    "for i, img in enumerate(imgs):\n",
    "    result = inference_vid(vid_model, img, frame_id=i)\n",
    "    vid_model.show_result(\n",
    "            img,\n",
    "            result,\n",
    "            wait_time=int(1000. / imgs.fps),\n",
    "            out_file=f'{out_path}/{i:06d}.jpg')\n",
    "    prog_bar.update()\n",
    "\n",
    "# 生成预测视频\n",
    "print(f'\\n making the output video at {output} with a FPS of {imgs.fps}')\n",
    "mmcv.frames2video(out_path, output, fps=imgs.fps, fourcc='mp4v')\n",
    "out_dir.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2ba7b-7206-4ca4-acf8-67959c77c86c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 视频实例分割 Video Instance Segmentat （VIS）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a8460-d436-4435-94ba-f7755db6f1d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 命令行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22dd1c9-938a-4c7e-8dd0-5b759a815b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-21 13:01:54,504 - mmtrack - INFO - initialize MaskRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth'}\n",
      "2022-04-21 13:01:54,505 - mmcv - INFO - load model from: https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth\n",
      "2022-04-21 13:01:54,505 - mmcv - INFO - load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth\n",
      "Downloading: \"https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth\" to /home/featurize/.cache/torch/hub/checkpoints/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth\n",
      "100%|████████████████████████████████████████| 170M/170M [00:01<00:00, 92.8MB/s]\n",
      "2022-04-21 13:01:56,586 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([41, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([41]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([160, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([160]).\n",
      "size mismatch for roi_head.mask_head.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([40, 256, 1, 1]).\n",
      "size mismatch for roi_head.mask_head.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([40]).\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmtracking/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth\n",
      "Downloading: \"https://download.openmmlab.com/mmtracking/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth\" to /home/featurize/.cache/torch/hub/checkpoints/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth\n",
      "100%|████████████████████████████████████████| 222M/222M [00:02<00:00, 91.4MB/s]\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 4.2 task/s, elapsed: 24s, ETA:     0smaking the output video at outputs/B3_VIS_masktrack_rcnn.mp4 with a FPS of 24\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 24.8 task/s, elapsed: 4s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "!python demo/demo_mot_vis.py \\\n",
    "        configs/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019.py \\\n",
    "        --checkpoint https://download.openmmlab.com/mmtracking/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth \\\n",
    "        --input data/mot_people_short.mp4 \\\n",
    "        --output outputs/B3_VIS_masktrack_rcnn.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276218f-702f-4e58-8546-ad4e9eb60bb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7abe056-fc39-44ea-a8af-e3384623f223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 13:02:31,929 - mmtrack - INFO - initialize MaskRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth'}\n",
      "2022-04-21 13:02:31,930 - mmcv - INFO - load model from: https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth\n",
      "2022-04-21 13:02:31,931 - mmcv - INFO - load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth\n",
      "2022-04-21 13:02:32,061 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([41, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([41]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([160, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([160]).\n",
      "size mismatch for roi_head.mask_head.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([40, 256, 1, 1]).\n",
      "size mismatch for roi_head.mask_head.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([40]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmtracking/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 4.2 task/s, elapsed: 23s, ETA:     0s\n",
      " making the output video at outputs/B4_VIS_masktrack_rcnn.mp4 with a FPS of 24.652929091701427\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 25.5 task/s, elapsed: 4s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "import tempfile\n",
    "from mmtrack.apis import inference_mot, init_model\n",
    "\n",
    "# 输入输出视频路径\n",
    "input_video = 'data/mot_people_short.mp4'\n",
    "output = 'outputs/B4_VIS_masktrack_rcnn.mp4'\n",
    "\n",
    "# 指定 config 配置文件 和 模型权重文件，创建模型\n",
    "vis_config = './configs/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019.py'\n",
    "vis_checkpoint = 'https://download.openmmlab.com/mmtracking/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth'\n",
    "vis_model = init_model(vis_config, vis_checkpoint, device='cuda:0')\n",
    "\n",
    "# 读入待预测视频\n",
    "imgs = mmcv.VideoReader(input_video)\n",
    "prog_bar = mmcv.ProgressBar(len(imgs))\n",
    "out_dir = tempfile.TemporaryDirectory()\n",
    "out_path = out_dir.name\n",
    "\n",
    "# 逐帧输入模型预测\n",
    "for i, img in enumerate(imgs):\n",
    "    result = inference_mot(vis_model, img, frame_id=i)\n",
    "    vis_model.show_result(\n",
    "            img,\n",
    "            result,\n",
    "            wait_time=int(1000. / imgs.fps),\n",
    "            out_file=f'{out_path}/{i:06d}.jpg')\n",
    "    prog_bar.update()\n",
    "    \n",
    "\n",
    "print(f'\\n making the output video at {output} with a FPS of {imgs.fps}')\n",
    "\n",
    "# 生成预测视频\n",
    "mmcv.frames2video(out_path, output, fps=imgs.fps, fourcc='mp4v')\n",
    "out_dir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c2467d-b944-4c50-babb-5ef7cfe6c7df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
